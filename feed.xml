<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://mikezhou.me/feed.xml" rel="self" type="application/atom+xml"/><link href="https://mikezhou.me/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-10-22T22:52:45+00:00</updated><id>https://mikezhou.me/feed.xml</id><title type="html">blank</title><subtitle>Mike Zhou - Computer Science and Mathematics student at the University of Pennsylvania (UPenn). Undergraduate researcher at Penn&apos;s Cognitive Computation Group working on NLP and machine learning. </subtitle><entry><title type="html">The Gradient of Thought: Reasoning as a Natural Objective for Alignment</title><link href="https://mikezhou.me/blog/2025/gradient-of-thought/" rel="alternate" type="text/html" title="The Gradient of Thought: Reasoning as a Natural Objective for Alignment"/><published>2025-10-22T18:34:00+00:00</published><updated>2025-10-22T18:34:00+00:00</updated><id>https://mikezhou.me/blog/2025/gradient-of-thought</id><content type="html" xml:base="https://mikezhou.me/blog/2025/gradient-of-thought/"><![CDATA[<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-0823RLC0T3"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0823RLC0T3");</script> <p>Large language models (LLMs) learn in a remarkably simple way: by predicting the next token in a sequence. During pre-training, they process vast corpora and adjust parameters $\theta$ so that the probability assigned to the correct next token,</p> \[p_\theta(x_t \mid x_{&lt;t}),\] <p>steadily rises. This is the familiar language-modeling (cross-entropy) objective.</p> <p>At a high level, an LLM learns a map from <em>context</em> (what has already been seen) to <em>expectation</em> (a distribution for what should come next). Fine-tuning, or <em>post-training</em>, refines this map for specific tasks: multi-step reasoning, following instructions, calibration, and so on.</p> <p>A by-now standard empirical observation (see, e.g., Wei et al.) is that prompting models to produce <em>Chain-of-Thought</em> (CoT), step-by-step intermediate explanations, often yields striking improvements on reasoning tasks. Appending “Let’s think step by step” induces the model to unfold a short sequence of intermediate tokens that articulate a path:</p> <blockquote style="margin-left: 2.5em; margin-right: 2.5em; font-size: 0.9em; color: #444; font-style: italic;"> "To solve this, first note the number is even; therefore dividing by two gives \dots" </blockquote> <p>Why should such intermediate text help?</p> <h2> An Information-Theoretic Perspective </h2> <p>At bottom, next-token prediction is an exercise in uncertainty management. The <em>surprisal</em> of a token $x_t$ given its context $x_{&lt;t}$ is</p> \[\surp(x_t \mid x_{&lt;t}) \;=\; -\log p_\theta(x_t \mid x_{&lt;t}),\] <p>measured in bits. Surprisal counts how many “yes/no” questions one would need, on average, to identify the correct token under the model’s own distribution. High surprisal signals a difficult prediction (the model did not expect this token); low surprisal signals an easy one.</p> <p>When a question is hard, we rarely vault straight to the answer. We instead lay down stepping stones: small statements that are easy to verify, each making the next step easier. CoT plays the same role for a model. Rather than a single long, unlikely jump $q \to a$, we nudge the model to traverse a short path</p> \[q \;\to\; r_1 \;\to\; r_2 \;\to\; \cdots \;\to\; r_k \;\to\; a,\] <p>so that each conditional $p_\theta(r_i \mid q, r_{&lt;i})$ and $p_\theta(a \mid q, r_{1:k})$ is higher than it would have been without the preceding scaffolding. The informational load that would otherwise concentrate in a single cliff-edge step becomes distributed across the sentence in several gentler slopes.</p> <h2> Chain-of-Thought and Post Training Gradients </h2> <p>One can think of post-training not as the acquisition of new facts, but as the adjustment of geometry within a model that already knows much. Because language models are optimized under a cross-entropy objective, surprisal and gradient behavior are intimately linked: when the model’s predictions are more evenly distributed, its updates become steadier. Fine-tuning on Chain-of-Thought (CoT) prompt–answer pairs achieves precisely this effect. The reasoning prefix redistributes surprisal across tokens, smoothing the loss surface and dampening abrupt fluctuations in the gradient with respect to the logits—what we may call gradient spikes. In essence, CoT supervision transforms learning from a sequence of sharp corrections into a flow of gentle, coherent updates.</p> <p><br/></p> <div class="card mt-3 p-3"> <h6 class="card-title font-weight-medium">Lemma 1</h6> <div class="card-text"> <p>The partial derivative of the loss with respect to $y_k$ is simply the model’s predicted probability of that token minus the true label. In other words, $$\frac{\partial \mathcal{L}}{\partial y_k} = p_\theta(y_k \mid c_t) - \mathbb{I}\{y_k = x_{t+1}\}, $$ where $x_{t+1}$ is the correct next token in the training data. </p> </div> </div> <p><br/></p> <p><em>Proof.</em> Write $Z = \sum_j e^{y_j}$ and $p_i = e^{y_i}/Z$.</p> <p>For each $i$,</p> \[\log p_i = y_i - \log Z,\] <p>so</p> \[\frac{\partial}{\partial y_k} \log p_i = \frac{\partial y_i}{\partial y_k} - \frac{\partial \log Z}{\partial y_k} = \mathbb{I}\{i = k\} - \frac{1}{Z} \frac{\partial Z}{\partial y_k}\] \[= \mathbb{I}\{i = k\} - \frac{e^{y_k}}{Z} = \mathbb{I}\{i = k\} - p_k.\] <p>Therefore,</p> \[\frac{\partial \mathcal{L}}{\partial y_k} = -\sum_{i=1}^V q(i) \frac{\partial}{\partial y_k} \log p_i = -\sum_i q(i)\bigl(\mathbb{I}\{i = k\} - p_k\bigr)\] \[= -q(k) + p_k \sum_i q(i) = p_k - q(k),\] <p>since $\sum_i q(i) = 1$.</p> <p>Specializing to the one-hot case $q = \mathbb{I}{k = x_{t+1}}$ gives</p> \[\frac{\partial \mathcal{L}}{\partial y_k} = p_k - \mathbb{I}\{k = x_{t+1}\},\] <p>as claimed. $\square$</p> <p>We now use this to connect the size of the gradient to the model’s probability distribution.</p> <p><br/></p> <div class="card mt-3 p-3"> <h6 class="card-title font-weight-medium">Lemma 2</h6> <div class="card-text"> <p>Let $g$ be the loss gradient in respect to model logits. If $\|g\| &gt; \tau$, then $$ 1 - \sqrt{\tau} \leq \theta(x_{t+1} \mid c_t) \leq 1 - \sqrt{\tfrac{\tau}{2}}. $$ </p> </div> </div> <p><br/></p> <p><em>Proof.</em> Let $p$ denote the probability vector $p_\theta(\cdot \mid c_t)$ and $p_x$ as $p_\theta(x_{t+1} \mid c_t)$ represent the probability vector of From Lemma 1, the gradient with respect to the logits satisfies</p> \[\|g\|^2 = (1 - p_x)^2 + \sum_{y_i \neq x_{t+1}} p_\theta(y_i \mid c_t)^2.\] <p>Rewriting,</p> \[\|g\|^2 = \|p\|_2^2 - 2p_x + 1.\] <p>Since the entries of $p_\theta$ are nonnegative and sum to one,</p> \[\|p\|_2^2 \leq p_x^2 + (1 - p_x)^2.\] <p>Substituting this bound gives</p> \[\|g\|^2 \leq 2(1 - p_x)^2.\] <p>Hence, if $|g| &gt; \tau$, it follows that</p> \[p_x \leq 1 - \sqrt{\tfrac{\tau}{2}},\] <p>Similarly, we can use the bound</p> \[|p\|_2^2 \geq p^2\] <p>to get that</p> \[p_x \geq 1 - \sqrt{\tau}. \square\] <p>The magnitude of the gradient spike during training is thus largely governed by the tail of the model’s probability distribution: when the model assigns high probability to the correct token, the gradient necessarily remains small. Reasoning traces are easier to for the model to predict, effectively shifting the distribution of the correct token forward, moving the tail upwards and thereby reducing the frequency and severity of large gradients in practice.</p> <p>Of course, if we used only the preceding lemma, one could only guarantee this in theory when the shift in probability exceeds roughly $\sqrt{\tau_{\text{direct}}}(1 - \sqrt{2}/2)$ in factor; the verification of this is left as an exercise to the reader. However, the inequalities employed above are somewhat generous, and in most realistic settings the stability improvement from CoT training probably appears far stronger than this conservative bound would suggest.</p> <h2> From Surprise to Stability </h2> <p>From this gradient perspective, the benefits of Chain-of-Thought supervision extend beyond teaching the model to just reason: they reveal reasoning itself as a task that naturally aligns the model’s learning dynamics with the behaviors we seek to cultivate. Training on reasoning sequences elicit smaller, steadier gradient updates. These tempered updates allow the model’s latent capacities—abstraction, consistency, self-monitoring—to emerge without being drowned out by gradient noise, while also keeping learning trajectories closer to the model’s original pre-trained distribution. In this way, the reasoning objective acts as an elicitation prior: it guides optimization toward coherent, human-aligned behavior through the intrinsic structure of the task. This demonstrates that reasoning is not just a tool for alignment: it is also a natural training objective for it.</p> <p>Reasoning sequences in this light act as a variational regularizer on the cross-entropy objective, implicitly minimizing curvature in the loss surface. But beyond stabilizing optimization, these gentler updates confer several deeper benefits. In fine-tuning, where a narrow slice of data adjusts a model with billions of parameters, stability matters as much as accuracy. Smoother gradients prevent overcorrection and reduce the risk of catastrophic forgetting, allowing the model to incorporate new reasoning patterns without erasing the representations that support them. Intuitively, we are teaching the model to reason more, not to memorize differently: the training signal refines the structure of thought rather than replacing its contents. This makes reasoning supervision doubly valuable: it extends the model’s abilities while preserving the foundation it was built upon.</p> <p>This perspective helps illuminate why many modern alignment strategies, like the “reasoning-first” design of the o1 training process, prove so effective. Most textbook data, for example, announces the answer before revealing the logic, preserving a sharp spike in surprisal that gradients must struggle to descend. Reasoning-first data, by contrast, tilts that spike into a staircase, letting probability mass shift forward gradually as intermediate steps unfold. The resulting model learns to reason and to learn in smaller, steadier increments.</p> <p>Geometrically, this translates to a refinement of the model’s internal landscape. Pre-training yields a vast but rugged terrain, full of steep cliffs where token probabilities shift abruptly from one step to the next. Post-training on reasoning traces acts less like the addition of new knowledge and more like a smoothing operation across this surface. The same information remains, but its contours soften; gradients that once fluctuated violently begin to flow coherently along intermediate steps. The model does not merely learn new facts—it learns to traverse its own knowledge more gracefully. In the end, the gradient tells a simple story: reasoning is a way of making prediction coherent. When a model learns to smooth its own landscape—distributing complexity over time and thought—it becomes not only a better reasoner, but a gentler learner.</p>]]></content><author><name></name></author><category term="math"/><category term="nlp"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Diophantine Approximation and Transcendental Numbers</title><link href="https://mikezhou.me/blog/2025/diophantine-approximation-and-transcendental-numbers/" rel="alternate" type="text/html" title="Diophantine Approximation and Transcendental Numbers"/><published>2025-04-12T22:48:00+00:00</published><updated>2025-04-12T22:48:00+00:00</updated><id>https://mikezhou.me/blog/2025/diophantine-approximation-and-transcendental-numbers</id><content type="html" xml:base="https://mikezhou.me/blog/2025/diophantine-approximation-and-transcendental-numbers/"><![CDATA[<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-0823RLC0T3"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0823RLC0T3");</script> <p>Many numbers we encounter in everyday life–even those that seem impossibly complex–fall into categories we’ve known for centuries: rational numbers, which can be written in the form \(p/q\), and algebraic numbers, which can be written as the root of some rational polynomial. But beyond these well-behaved figures lies a stranger world: the realm of transcendental numbers.</p> <p>Transcendental numbers are numbers that cannot be expressed as solutions to polynomial equations with integer coefficients. Up until the mid-19th century, it was unresolved whether any transcendental numbers existed. In fact, it is extremely hard to even prove that a number may even be transcendental. While Liouville had proven the existence of transcendental numbers in 1844, it wasn’t until 1873 that Hermite proved \(e\) is transcendental, followed by Lindemann’s proof of \(\pi\)’s transcendence in 1882. Liouville’s approach, centered on approximation properties of numbers, provided the first concrete examples of transcendental numbers and established a powerful criterion for transcendence.</p> <p>To understand the intuition of Liouville’s approach, let’s first walk through Cantor’s proof of the existence of transcendental numbers. To understand why transcendental numbers must exist, we begin with a key concept from set theory: the idea of countable and uncountable sets.</p> <p>A set is said to be <b>countable</b> if its elements can be placed into a one-to-one correspondence with the natural numbers \(\mathbb{N} = \{1, 2, 3, \dots\}\). That is, we can enumerate the elements in a list: \(x_1, x_2, x_3, \dots\). Examples of countable sets include:</p> <ul> <li>The set of natural numbers \(\mathbb{N}\)</li> <li>The set of integers \(\mathbb{Z}\)</li> <li>The set of rational numbers \(\mathbb{Q}\)</li> </ul> <p>For example, \(\mathbb{Q}\) is in one one-to-one correspondence to \(\mathbb{N}\) by “counting” rationals in order by the sum of their numerator and denominator (ie. \(1 / 1\) goes first, \(1 / 2\) goes second, \(2 / 1\) goes third, \(1 / 3\) goes fourth, \(2 / 2\) goes fifth, \(3 / 1\) goes sixth, etc). Similar to the proof that \(\mathbb{Q}\) is countable, the set of all integer polynomials is also countable, meaning that the set of all algebraic numbers is countable.</p> <p>Since all algebraic numbers are countable, it would suffice to show that the reals are uncountable in order to demonstrate the existence of transcendental numbers. To do this, Cantor supposed for contradiction that all real numbers in the interval \((0, 1)\) can be listed:</p> \[r_1 = 0.a_{11}a_{12}a_{13}\dots\] \[r_2 = 0.a_{21}a_{22}a_{23}\dots\] \[r_3 = 0.a_{31}a_{32}a_{33}\dots\] \[\vdots\] <p>Now construct a new number \(r \in (0,1)\) by altering the diagonal digits:</p> \[b_i = \begin{cases} 1 &amp; \text{if } a_{ii} \neq 1 \\ 0 &amp; \text{if } a_{ii} = 1 \end{cases}\] <p>and define</p> \[r = 0.b_1 b_2 b_3 \dots\] <p>By construction, \(r\) differs from each \(r_i\) in at least the \(i\)-th decimal place. Therefore, \(r\) is not in the list, contradicting our assumption that all real numbers in \((0,1)\) were listed.</p> <p>From this result, we can make a clear observation. While the rational and algebraic numbers are scattered densely across the real line, they form only a countable skeleton. The transcendental numbers, in contrast, fill in the uncountable “gaps” between them, making up almost all of the real number continuum. In essence, because transcendental numbers fill in these gaps between rationals, they can reveal themselves through how well they can be approximated by rationals. Roughly speaking, an irrational number that can be approximated by rationals better than any other number must be transcendental.</p> <h3>Liouville's Insight and Transcendental Numbers</h3> <p>Though predating Cantor, Liouville’s crucial insight, dating back to 1844, was exactly this: to understand just how well irrational algebraic numbers can be approximated by rationals—and how that imposes deep structural limitations. To demonstrate this, he constructed what is now known as the <b>Liouville constant</b>:</p> \[L = \sum_{n=1}^{\infty} \frac{1}{10^{n!}} = 0.110001000000000000000001000\ldots\] <p>Now you might ask: what does it mean for a number to be “better” approximated by a rational? After all, every real number admits rational approximations. The usual intention is to compare the denominator of the approximating fraction with the size of the error. An approximation is unusually good if the number can be matched by a rational whose denominator is small relative to the error term.</p> <p>Let’s begin with the key result:</p> <p><strong>Theorem 1 (Liouville).</strong> <em>Let</em> \(\alpha\) <em>be an irrational algebraic number of degree</em> \(n &gt; 1\). <em>Then there exists a positive constant</em> \(A\) <em>such that for all integers</em> \(p, q\) <em>with</em> \(q &gt; 0\), we have:</p> \[\left\vert \alpha - \frac{p}{q}\right\vert &gt; \frac{A}{q^n}\] <p>In other words, irrational algebraic numbers can’t be too well approximated by rational numbers, and any number that can be approximated well by a rational of small denominator must be transcendental.</p> <p><em>Proof.</em> Let \(f(x) = \sum a_k x^k\) be the minimal polynomial of \(\alpha\) with integer coefficients. Since \(f(\alpha) = 0\), we’ll examine how \(f\) behaves near \(\alpha\).</p> <p>By the fundamental theorem of algebra, \(f\) has at most \(n\) roots. This means there exists some \(\delta_1 &gt; 0\) such that if \(0 &lt; \vert x - \alpha \vert &lt; \delta_1\), then \(f(x) \neq 0\).</p> <p>Also, since \(f'(\alpha) \neq 0\) and \(f'\) is continuous, we can find \(\delta_2 &gt; 0\) and a bound \(M &gt; 0\) such that if \(\vert x - \alpha \vert &lt; \delta_2\), then</p> \[0 &lt; |f'(x)| \leq M\] <p>Let \(\delta = \min(\delta_1, \delta_2)\). If a rational number \(\frac{p}{q}\) lies within \(\delta\) of \(\alpha\), then by the Mean Value Theorem, there exists \(x_0\) between \(p/q\) and \(\alpha\) such that</p> \[f'(x_0) = \frac{f(\alpha) - f(p/q)}{\alpha - p/q}\] <p>Since \(f(\alpha) = 0\) and \(f(p/q) \neq 0\), we rearrange:</p> \[\vert \alpha - p/q \vert = \frac{\vert f(p/q) \vert}{\vert f'(x_0) \vert}\] <p>Now consider the value of \(f(p/q)\). Since \(f\) has integer coefficients,</p> \[f(p/q) = \frac{1}{q^n} \sum_{k=0}^{n} a_k p^k q^{n-k}\] <p>This sum is an integer, and if \(f(p/q) \neq 0\), its absolute value is at least 1. So,</p> \[|\alpha - p/q| \geq \frac{1}{|f'(x_0)|} \cdot \frac{1}{q^n} \geq \frac{1}{M} \cdot \frac{1}{q^n}\] <p>Setting \(A = 1/M\), we get the desired bound.</p> <p>We then define a <strong>Liouville number</strong> as an irrational number \(x\) such that, for every integer \(n &gt; 0\), there exists a pair \((p, q)\) satisfying</p> \[\left\vert x - \frac{p}{q} \right\vert &lt; \frac{1}{q^n}\] <p>These numbers are, in a sense, <em>too well</em> approximated by rationals to be algebraic, and are better approximated by rationals than any other algebraic number.</p> <p><strong>Theorem 2.</strong> <em>Every Liouville number is transcendental.</em></p> <p><em>Proof.</em> Suppose not—suppose there’s a Liouville number \(x\) that is algebraic of degree \(d &gt; 1\). Then by Theorem 1, there is a constant \(A &gt; 0\) such that:</p> \[\left\vert x - \frac{p}{q} \right\vert &gt; \frac{A}{q^d}\] <p>for all rational numbers \(p/q\).</p> <p>But the definition of Liouville number tells us that for any \(n &gt; d\), we can find \(p/q\) such that</p> \[\left\vert x - \frac{p}{q} \right\vert &lt; \frac{1}{q^n}\] <p>For sufficiently large \(n\), we have the inequality</p> \[\frac{1}{q^n} &lt; \frac{A}{q^d}\] <p>contradicting the lower bound. Therefore, \(x\) cannot be algebraic.</p> <p>Returning to Liouville’s original construction:</p> \[L = \sum_{n=1}^{\infty} \frac{1}{10^{n!}}\] <p>We’ll show that this specific number satisfies the Liouville condition.</p> <p><strong>Theorem 3.</strong> <em>The Liouville constant</em> \(L\) <em>is transcendental.</em></p> <p><em>Proof.</em> For any \(m &gt; 0\), define a rational approximation:</p> \[L_m = \sum_{n=1}^{m} \frac{1}{10^{n!}}\] <p>This is a rational number with denominator \(10^{m!}\). The error between \(L\) and \(L_m\) is:</p> \[|L - L_m| = \sum_{n=m+1}^{\infty} \frac{1}{10^{n!}} = \frac{1}{9 \cdot 10^{(m+1)! - 1}}\] <p>Since \((m+1)! - 1 \geq m!(m)\) for large enough \(m\), we can write:</p> \[|L - L_m| &lt; \frac{1}{10^{m!(m)}} = \frac{1}{(10^{m!})^{m}} = \frac{1}{q^{m}}\] <p>where \(q = 10^{m!}\). Hence, by Theorem 2, \(L\) is transcendental.</p> <h3>Concluding Remarks: Roth’s Theorem on Diophantine Approximation</h3> <p>Liouville’s theorem was eventually sharpened in 1955 by Klaus Roth, who proved a striking improvement:</p> <p><strong>Theorem 4 (Roth).</strong> <em>Let</em> \(\alpha\) <em>be an irrational algebraic number. Then for every</em> \(\epsilon &gt; 0\)<em>, there exist only finitely many rational numbers \(p/q\) such that</em></p> \[\left\vert \alpha - \frac{p}{q} \right\vert &lt; \frac{1}{q^{2 + \epsilon}}\] <p>This result shows that the exponent \(2\) is essentially optimal for algebraic irrationals: they cannot be approximated better than order \(1/q^2\), no matter how high their degree.</p> <p>This study of how well real numbers can be approximated by rational ones is known as Diophantine Approximation. At first glance, this seems like a simple analytical question—how close can a fraction get to a given real number? But as it turns out, the answer is tightly constrained by number-theoretic structure. It forms in essence a conceptual bridge between analysis and number theory, revealing how the seemingly soft idea of “closeness” is secretly governed by hard algebraic facts. For instance, while any real number can be approximated by rationals, not all can be approximated equally well—and that difference can be telling.</p> <p>Transcendental numbers—those that satisfy no algebraic equation with integer coefficients—can often be detected by their approximation behavior. Liouville’s insight was not just a clever construction—it was the beginning of a powerful philosophy: that transcendence can be sensed in how a number weaves through the gaps left by the rationals. Some gaps are too intricate for algebra to capture.</p>]]></content><author><name></name></author><category term="math"/><category term="number-theory"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Hardy-Ramanujan with probabilistic method</title><link href="https://mikezhou.me/blog/2024/distinct-prime-factors-problem/" rel="alternate" type="text/html" title="Hardy-Ramanujan with probabilistic method"/><published>2024-10-21T13:57:00+00:00</published><updated>2024-10-21T13:57:00+00:00</updated><id>https://mikezhou.me/blog/2024/distinct-prime-factors-problem</id><content type="html" xml:base="https://mikezhou.me/blog/2024/distinct-prime-factors-problem/"><![CDATA[<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-0823RLC0T3"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0823RLC0T3");</script> <p>One of my favourite examples of the probabilistic method at work is the Hardy–Ramanujan theorem. It says that if you take a large integer \(x\), the number of distinct prime factors it has, written \(\omega(x)\), is usually very close to \(\log\log x\). More precisely, the fluctuations are typically no larger than about \(\sqrt{\log\log x}\).</p> <p>At first sight this is the kind of statement one might expect to need advanced analytic tools. After all, it concerns the distribution of prime factors, which is usually a delicate subject. But in fact the proof rests on a very simple probabilistic observation; to sketch the main one out, if a random variable’s expectation and variance are “close enough”, one can use Chebyshev’s inequality to show that almost all cases of this random variable are assymptotically equal to its expectation with only a vanishing number of exceptions. Thus, if the expected value of \(\omega(x)\) is close to its variance, we can use clever bounds to find an elementary proof to a seemingly difficult number theoretic problem.</p> <p><b>Theorem (Ramanujan).</b> Let \(\phi\) be any function that grows arbitrarily slowly to infinity. For large enough \(N\), we have that \(\vert \{x \leq N :\vert \omega(x) - \text{log}(\text{log}(x)) \vert &gt; \phi(x)\sqrt{\text{log}(\text{log}(x))} \} \vert = o(N)\)</p> <p>To prove this statement, it suffices to show that \(\textbf{P}( \vert \omega(x) - \text{log}(\text{log}(x)) \vert &gt; \phi(x)\sqrt{\text{log}(\text{log}(x) )}) = o(1)\). This looks like an application of Chebyshev’s inequality.</p> <p>We can start by defining a random variable \(X\) denoting the number of prime divisors a randomly selected \(x \leq N\) has that are each less than \(N^{\frac{1}{3}}\) (notice that \(x\) can only have at most 3 prime factors larger than \(N^{\frac{1}{3}}\), so \(X\) will only be off by a constant additive factor). For a technical detail we will see later, it will be easier to analyze prime factors less than \(N^{\frac{1}{3}}\) rather than \(N\).</p> <p>Since the probability that a prime \(p\) divides \(x\) is \(\frac{1}{p} + O\left(\frac{1}{N}\right)\), we have that</p> \[\textbf{E}[X] = \sum_{p \leq N^{\frac{1}{3}}} \frac{1}{p} + O\left(\frac{1}{N}\right)\] <p>by simply letting \(X\) be the sum of indicator variables representing whether a prime divides \(x\) or not. Since each indicator variable is a Bernoulli random variable, their individual variances are \(\textbf{P}(p \mid x) - \textbf{P}(p \mid x)^2\), meaning that</p> \[\textbf{Var}(X) = \left(\sum_{p \leq N^{\frac{1}{3}}} \frac{1}{p} - \frac{1}{p^2} + O\left( \frac{1}{N} \right) \right) - 2\left(\sum_{p &lt; q \leq N^{\frac{1}{3}}} \textbf{E}[(\mathbb{I}(p \mid x))(\mathbb{I}(q \mid x))] - \textbf{E}[(\mathbb{I}(p \mid x))]\textbf{E}[(\mathbb{I}(q \mid x))] \right).\] <p>Notice that \((\mathbb{I}(p \mid x))(\mathbb{I}(q \mid x)) = 1\) if and only if both \(p\) and \(q\) divide \(x\). This is the same as if \(pq\) divides \(x\), which has probability \(\frac{1}{pq} + O\left(\frac{1}{N}\right)\). Thus, <br/> <br/></p> \[\textbf{E}[(\mathbb{I}(p \mid x))(\mathbb{I}(q \mid x))] - \textbf{E}[(\mathbb{I}(p \mid x))]\textbf{E}[(\mathbb{I}(q \mid x))]\] <p><br/></p> \[= \frac{1}{pq} + O\left(\frac{1}{N}\right) - \left(\frac{1}{p} + O\left(\frac{1}{N}\right)\right) \left(\frac{1}{q} + O\left(\frac{1}{N}\right) \right) = O\left(\frac{1}{N}\right)\] <p>and</p> \[\textbf{Var}(X) = \left(\sum_{p \leq N^{\frac{1}{3}}} \frac{1}{p} - \frac{1}{p^2} + O\left( \frac{1}{N}\right) \right) + 2\left(\sum_{p &lt; q \leq N^{\frac{1}{3}}} O\left( \frac{1}{N}\right)\right).\] <p>Since we are summing at most \(N^{\frac{2}{3}}\) number of terms (the technical detail we discussed earlier), we have that each \(O(\frac{1}{N})\) vanishes. We can then use Merten’s estimates and the fact that the sum of reciprical of squares converges to get that</p> \[\textbf{E}[X] = \text{log}(\text{log}(N)) + O(1)\] \[\textbf{Var}(X) = \text{log}(\text{log}(N)) + O(1)\] <p>and then by Chebyshev’s inequality and the fact that \(\text{log}(\text{log}(x)) = \text{log}(\text{log}(N)) + O(1)\) with probability \(1 - o(1)\), we have that</p> \[\textbf{P}\left( \vert \omega(x) - \text{log}(\text{log}(x)) \vert &gt; \phi(x)\sqrt{\text{log}(\text{log}(x) )}\right) \ll o(1) + \frac{\text{log}(\text{log}(N))}{\phi(x)^2\text{log}(\text{log}(N))} = o(1)\] <p>meaning that</p> \[\vert \{x \leq N :\vert \omega(x) - \text{log}(\text{log}(x)) \vert &gt; \phi(x)\sqrt{\text{log}(\text{log}(x))} \} \vert = o(N).\] <p><br/></p> <h3> Note on Merten Estimates </h3> <p>Merten’s estimates can be derived using elementary techniques. All you really need is that \(\text{log}(n!) = n\text{log}(n) + O(n)\), as</p> \[\text{log}(n!) = \sum_{p \leq n} \text{log}(p) \lfloor \frac{n}{p} \rfloor = O(n) + n\sum_{p \leq n} \frac{\text{log}(p)}{p}\] \[\sum_{p \leq n}\frac{\text{log}(p)}{p} = \text{log}(n) + O(1)\] <p>Then, using summation by parts on \(\frac{\text{log}(p)}{p}\) and \(\frac{1}{\text{log}(p)}\), we have that</p> \[\sum_{p \leq n} \frac{1}{p} = \text{log}(\text{log}(n)) + O(1)\]]]></content><author><name></name></author><category term="math"/><category term="combinatorics"/><category term="number-theory"/><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Minimum number of lines from non-collinear points</title><link href="https://mikezhou.me/blog/2024/non-collinear-points-problem/" rel="alternate" type="text/html" title="Minimum number of lines from non-collinear points"/><published>2024-09-16T16:42:00+00:00</published><updated>2024-09-16T16:42:00+00:00</updated><id>https://mikezhou.me/blog/2024/non-collinear-points-problem</id><content type="html" xml:base="https://mikezhou.me/blog/2024/non-collinear-points-problem/"><![CDATA[<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-0823RLC0T3"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-0823RLC0T3");</script> <p>As I’ve been reading more about June Huh’s work with the Dowling-Wilson conjecture, I’ve become more and more interested in algebraic methods within combinatorics. More recently, I’ve come across a very cute problem with a very neat solution, inspired by simple ideas from linear algebra.</p> <p><b>Problem 1.</b> What is the minimum number of lines \(n\) non-collinear points form if all lines are drawn between points?</p> <p>It is easy to see that we can achieve \(n\) lines by simply leaving \(n - 1\) collinear points on a line and the last point off the line. Indeed, this is the best case possible.</p> <p>To demonstrate why, we can assign variables \(x\) to each of the points, and define a system of equations as:</p> \[\sum_{j: \text{ } x_j \in l_i} x_j = 0.\] <p>That is, the sum of all the variables on line \(i\) is equal to 0. Assuming that there is a placement of \(n\) points that produces less than \(n\) lines, we will have at most \(n - 1\) equations and \(n\) variables, meaning that there exists a nontrivial solution (this is the key idea of the proof). Since the square of non-zero numbers is strictly larger than 0, it would make sense to introduce squares, so let’s square each equation and add them all up, like this:</p> \[\sum_{i = 1}^{m}\left(\sum_{j:\text{ } x_j \in l_i} x_j\right)^2 = \sum_{i = 1}^n a_i x_i^2 + 2\sum_{1 \leq i &lt; j \leq n} a_{i, j} x_i x_j = 0\] <p>where \(m\) is the number of lines, \(a_i\) is the number of lines that \(x_i\) shows up on, and \(a_{i, j}\) is the number of lines \(x_i\) and \(x_j\) show up on. Since our points are not all on a single line, \(a_i &gt; 1\), and since all lines are drawn between points and two points define a line, we have that \(a_{i, j}\) equals exactly 1. Thus,</p> \[0 = \sum_{i = 1}^n a_i x_i^2 + 2\sum_{1 \leq i &lt; j \leq n} a_{i, j} x_i x_j = \sum_{i = 1}^n (a_i - 1) x_i^2 + \left(\sum_{i = 1}^n x_i \right)^2.\] <p>Because we have a non-trivial solution and \(a_i &gt; 1\),</p> \[\sum_{i = 1}^n (a_i - 1) x_i^2 &gt; 0,\] <p>and</p> \[0 = \sum_{i = 1}^n (a_i - 1) x_i^2 + \left(\sum_{i = 1}^n x_i \right)^2 &gt; 0\] <p>gives a contradiction.</p>]]></content><author><name></name></author><category term="math"/><category term="combinatorics"/><summary type="html"><![CDATA[]]></summary></entry></feed>